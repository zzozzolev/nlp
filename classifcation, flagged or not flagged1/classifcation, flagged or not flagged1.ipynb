{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YBIGTA 10기 노혜미"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Classification, flagged or not flagged1 <br>- term existence와 tf-idf 이용하기"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv('Sheet_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>class</th>\n",
       "      <th>response_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>response_1</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>response_2</td>\n",
       "      <td>flagged</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>response_3</td>\n",
       "      <td>flagged</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>response_4</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>response_5</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  response_id        class                                      response_text\n",
       "0  response_1  not_flagged              I try and avoid this sort of conflict\n",
       "1  response_2      flagged  Had a friend open up to me about his mental ad...\n",
       "2  response_3      flagged  I saved a girl from suicide once. She was goin...\n",
       "3  response_4  not_flagged  i cant think of one really...i think i may hav...\n",
       "4  response_5  not_flagged  Only really one friend who doesn't fit into th..."
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### data 설명\n",
    "\n",
    "data는 캐글의 [여기](https://www.kaggle.com/samdeeplearning/deepnlp)에서 가져왔다. <br>\n",
    "치료 챗봇과 사람이 대화를 하는데 사람이 어떤 반응을 했냐에 따라 flagged가 될 수도 있고 not flagged가 될 수도 있다.<br>\n",
    "자세히는 모르겠지만, flagged가 되면 도움을 받으라고 챗봇이 메세지를 보낼 것이다.<br>\n",
    "우리가 풀어야 할 것은 test response가 주어졌을 때, **flagged에 해당하는지 not flagged에 해당하는지** 분류하는 것이다. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## deleting needless colunms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "data = data.drop(['Unnamed: 3', 'Unnamed: 4', 'Unnamed: 5', 'Unnamed: 6', 'Unnamed: 7'], axis=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data['response_text']\n",
    "y = data['class']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# term-existence를 이용한 문서간 유사도 구하기."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## text class"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# series를 list로 만든다.\n",
    "\n",
    "x_list = x.tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 단어들을 담을 set을 만들고 text를 공백기준으로 분리한 뒤, 해당 단어들의 punctuation을 없애고 소문자로 만든 뒤 words_set에 더해준다.\n",
    "# set을 이용하는 이유는 중복을 제거해주기 위해서이다.\n",
    "\n",
    "words_set = set()\n",
    "for text in x_list:\n",
    "    words = text.split()\n",
    "    for word in words:\n",
    "        words_set.add(word.strip(string.punctuation).lower())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 단어를 인덱싱한다.\n",
    "\n",
    "words_dic = {w: i for i, w in enumerate(words_set)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# ''는 아무의미가 없으므로 제거해준다.\n",
    "\n",
    "del words_dic['']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# sklearn의 DictVectorizer를 써서 one hot vector를 만들기 위해서는 딕셔너리의 리스트를 만들 필요가 있다. \n",
    "\n",
    "one_hot_dicts = []\n",
    "\n",
    "for text in x_list:\n",
    "    words = text.split()\n",
    "    one_hot_dic = {}\n",
    "    for word in words:\n",
    "        word = word.strip(string.punctuation).lower()\n",
    "        if word in words_dic.keys():\n",
    "            one_hot_dic[word] = 1\n",
    "    one_hot_dicts.append(one_hot_dic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I try and avoid this sort of conflict'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'and': 1,\n",
       " 'avoid': 1,\n",
       " 'conflict': 1,\n",
       " 'i': 1,\n",
       " 'of': 1,\n",
       " 'sort': 1,\n",
       " 'this': 1,\n",
       " 'try': 1}"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "one_hot_dicts[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.feature_extraction import DictVectorizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# DictVectorizer를 써서 one hot vector를 만들어준다.\n",
    "\n",
    "vec = DictVectorizer()\n",
    "one_hot = vec.fit_transform(one_hot_dicts).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "words dictionary length: 675\n",
      "one_hot length:  675\n",
      "[ 0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  1.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.  0.\n",
      "  0.  0.  0.  0.  0.  0.  0.  0.  0.]\n"
     ]
    }
   ],
   "source": [
    "print('words dictionary length:', len(words_dic))\n",
    "print('one_hot length: ', len(one_hot[0]))\n",
    "print(one_hot[0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "sklearn의 [train_test_split](http://scikit-learn.org/stable/modules/generated/sklearn.model_selection.train_test_split.html)을 더 권장한다..."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "80"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(one_hot)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 총 개수가 80개이므로 적당히 75개는 train으로 5개는 test로 한다.\n",
    "\n",
    "x_train = one_hot[:75]\n",
    "y_train = y[:75]\n",
    "x_test = one_hot[75:]\n",
    "y_test = y[75:]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "밑의 과정은 x_train의 one_hot이 잘 됐는지 확인하는 것이다. (필요 없다고 생각하면 생략 가능)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "index = []\n",
    "\n",
    "for i in range(len(x_train[0])):\n",
    "    if x_train[0][i] == 1.:\n",
    "        index.append(i)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[34, 55, 120, 290, 409, 529, 594, 619]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "and avoid conflict i of sort this try "
     ]
    }
   ],
   "source": [
    "for idx in index:\n",
    "    print(vec.get_feature_names()[idx], end= ' ')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'I try and avoid this sort of conflict'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_list[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "잘 된 걸 확인할 수 있다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### doc product?\n",
    "\n",
    "- 두 행렬을 곱할 때, 같은 행과 같은 열끼리 곱해주는 연산이다.\n",
    "- 예를 들면 행렬 A와 B가 있을 때, A의 1행1열과 B의 1행 1열을 곱해주는 식이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# one_hot 시킨 test response와 train response를 dot product한다.\n",
    "# 비슷한 단어가 많을 수록 dot product 값이 클 것이다. \n",
    "# 이전의 결과보다 크다면 현재 계산한 doc product의 결과를 추가해준다. \n",
    "\n",
    "sim_test = []\n",
    "\n",
    "for i in range(len(x_test)):\n",
    "    max_sum = 0.\n",
    "    max_idx = 0\n",
    "    for j in range(len(x_train)):\n",
    "        result = np.dot(x_test[i], x_train[j])\n",
    "        \n",
    "        if result > max_sum:\n",
    "            max_sum = result\n",
    "            max_idx = j\n",
    "            sim_test.append('test{} -> train{}'.format(i+len(x_train), max_idx))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['test75 -> train0',\n",
       " 'test75 -> train1',\n",
       " 'test75 -> train4',\n",
       " 'test75 -> train22',\n",
       " 'test75 -> train48',\n",
       " 'test76 -> train1',\n",
       " 'test76 -> train2',\n",
       " 'test76 -> train9',\n",
       " 'test76 -> train33',\n",
       " 'test76 -> train38',\n",
       " 'test77 -> train0',\n",
       " 'test77 -> train2',\n",
       " 'test77 -> train22',\n",
       " 'test77 -> train41',\n",
       " 'test78 -> train0',\n",
       " 'test78 -> train1',\n",
       " 'test78 -> train2',\n",
       " 'test78 -> train4',\n",
       " 'test78 -> train36',\n",
       " 'test78 -> train48',\n",
       " 'test79 -> train0',\n",
       " 'test79 -> train1',\n",
       " 'test79 -> train2',\n",
       " 'test79 -> train36',\n",
       " 'test79 -> train48']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 계속 비교해서 큰 걸 추가시켰으니, 맨 마지막에 있는 게 가장 큰 것이다. \n",
    "# 가장 큰 거만 출력하고 싶은데 못하겠다 ㅠㅠ...\n",
    "\n",
    "sim_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test와 가장 비슷하다고 나온 train의 결과값을 예측 list에 차례대로 추가해준다.\n",
    "\n",
    "predicted_list = []\n",
    "predicted_list.append(y_train[48])\n",
    "predicted_list.append(y_train[38]) \n",
    "predicted_list.append(y_train[41]) \n",
    "predicted_list.append(y_train[48]) \n",
    "predicted_list.append(y_train[48]) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "과연...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 개 중에 3 개 맞췄음.\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i+len(x_train)]==predicted_list[i]:\n",
    "        correct += 1 \n",
    "print(len(y_test), \"개 중에\", correct,\"개 맞췄음.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "크~구린(?) 방법임에도 반 이상은 맞았다.<br>\n",
    "데이터 자체가 워낙 작으니 이런 방법을 쓸 수 있던 것이지 데이터가 크다면 시도하면 안 된다...!<br>\n",
    "모든 단어들의 크기가 one hot vector의 크기가 되기 때문이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# TF-IDF를 이용한 문서간 유사도 구하기"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF ?\n",
    "\n",
    "참고:\n",
    "[위키백과](https://ko.wikipedia.org/wiki/TF-IDF)\n",
    "\n",
    "- term frequency - inverse document frequency의 약자이다.\n",
    "- 어떤 단어가 문서에서 **얼마나 중요한지**를 나타내는 통계적 수치.\n",
    "- 문서의 핵심어, 문서 간의 유사도등을 구할 때 이용할 수 있다.\n",
    "- 단어 빈도인 TF는 문서에서 단어가 얼마나 등장하는 지를 나타내는 값이다.\n",
    "- 역문서 빈도인 IDF는 단어가 여러 문서에서 잘 나오지 않는 지를 나타내는 값이다. 만약 여러 문서에서 잘 나타나지 않는 단어라면 IDF 값은 높아질 것이다.\n",
    "- 그리고 TF-IDF값은 이 두 값을 곱한 결과이다.\n",
    "- 예를 들어 보자. A,B,C,D 문서가 있을 때 A 문서내에 있는 ybigta라는 단어의 TF-IDF 값이 크다면 ybigta라는 단어는 A문서 내에서 많이 등장하고 다른 문서에서는 잘 등장하지 않는 단어이다. 따라서 A문서의 고유한 특성이 될 수 있다...! 즉, A문서를 대표하는 값으로 쓸 수 있다는 말이다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "소스 코드 출처: <br>\n",
    "https://stackoverflow.com/questions/12118720/python-tf-idf-cosine-to-find-document-similarity"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## skleran "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<80x660 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 1863 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "vec = TfidfVectorizer()\n",
    "x = vec.fit_transform(x_list)\n",
    "x"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### cosine similarity ?\n",
    "\n",
    "- 간단하게 말하면 두 비교 대상이 얼마나 가까운지를 측정하는 방법이다.<br>\n",
    "- 자세하게 알고 싶다면 [코사인 유사도](http://euriion.com/?p=548)를 참고하기 바란다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics.pairwise import linear_kernel\n",
    "\n",
    "# linear_kernel은 dot product이다.\n",
    "# doc product를 통해 cosine similarity를 구한다.\n",
    "\n",
    "cos_sim_list = []\n",
    "for i in range(75,80):\n",
    "    cosine_sim = linear_kernel(x[i], x).flatten()\n",
    "    cos_sim_list.append(cosine_sim)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# test 문장과 가장 가까운 문장을 2개 뽑는다.\n",
    "# argsort()는 가장 큰 값을 1으로 indexing하고 그 다음 큰 값을 2로 indexing하고 이를 \n",
    "# 이를 반복하는 메서드이다.\n",
    "\n",
    "rel_doc_list = []\n",
    "\n",
    "for i in range(len(cos_sim_list)):\n",
    "    related_doc_idx = cos_sim_list[i].argsort()[:-3:-1]\n",
    "    rel_doc_list.append(related_doc_idx)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([75, 48], dtype=int64),\n",
       " array([76, 38], dtype=int64),\n",
       " array([77, 32], dtype=int64),\n",
       " array([78, 57], dtype=int64),\n",
       " array([79, 63], dtype=int64)]"
      ]
     },
     "execution_count": 80,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# 2개를 뽑은 이유는 test역시 cosine similarity를 구할 때 고려됐으므로, 똑같은 문장 \n",
    "# 다음에 큰 값이 필요하기 때문이다.\n",
    "\n",
    "rel_doc_list"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# 가장 유사한 문장을 추가해준다.\n",
    "\n",
    "most_similar_doc = []\n",
    "\n",
    "most_similar_doc.append(y_train[48])\n",
    "most_similar_doc.append(y_train[38])\n",
    "most_similar_doc.append(y_train[32])\n",
    "most_similar_doc.append(y_train[57])\n",
    "most_similar_doc.append(y_train[63])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5 개 중에 4 개 맞췄음.\n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "for i in range(len(y_test)):\n",
    "    if y_test[i+len(x_train)]==most_similar_doc[i]:\n",
    "        correct += 1 \n",
    "print(len(y_test), \"개 중에\", correct,\"개 맞췄음.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "확실히 단순하게 one-hot vector를 이용하는 것보다 좋은 결과가 나왔다.<br>\n",
    "그리고 문서내에서 키워드를 추출하거나 비교를 할 때 tf-idf를 많이 이용하는 것 같다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- term-existence보다는 tf-idf를 이용하자~"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Reference\n",
    "\n",
    "- https://www.lucypark.kr/slides/2015-pyconkr/#13\n",
    "- https://ko.wikipedia.org/wiki/TF-IDF\n",
    "- https://stackoverflow.com/questions/12118720/python-tf-idf-cosine-to-find-document-similarity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
