{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "YBIGTA 10기 노혜미 박승리"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# RNN을 이용한 Text Classification with tensorflow"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "본격적으로 들어가기에 잠깐...!<br>\n",
    "딥러닝을 이용해서 텍스트를 분류하는데는 사실 RNN도 쓰이고 CNN도 쓰인다!<BR>\n",
    "그럼 궁금한 점이 생길 것이다...<BR> RNN과 CNN은 각각 어떤 텍스트를 분류할 때 좋은 걸까?<br>\n",
    "일단 텍스트는 **순서**를 가지는 자료이기 때문에 RNN이 좀 더 자연스러운 접근 방법이다. 하지만 RNN은 느린 편이고 train하기에 불안정하다고 한다. (출처 글에 그렇게 나왔다.) CNN이 RNN보다 훨씬 계산 속도가 빠르다고 한다.<BR>\n",
    "이와 같이 RNN에서 어느 정도의 단점이 있더라도, 하려는 일이 long semantics이냐 feature detection이냐에 따라서 적합한 모델이 다르다고 한다.<BR>\n",
    "텍스트의 길이가 중요한 작업에서는 RNN을 쓰는 게 좋다고 한다. RNN은 이전의 자료에 대한 정보가 쭉 이어지기 때문이다.뭐 예를 들면, 질문하고 답하기, 번역 같은 곳에서 쓰이면 좋다고 한다.<BR>\n",
    "feature detection이 더 중요하다면 CNN이 더 좋다고 한다. 감정 찾기, 개체명(namedn entity) 같은 걸 찾는 작업이 이에 해당할 것이다.\n",
    "\n",
    "좀 더 자세하게 알고 싶다면 다음의 논문을 참고하길 바란다.<br>\n",
    "[ComparativeStudyofCNNandRNNforNaturalLanguageProcessing](https://arxiv.org/pdf/1702.01923...)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import argparse\n",
    "\n",
    "import sys\n",
    "\n",
    "import numpy as np\n",
    "\n",
    "import pandas as pd\n",
    "\n",
    "from sklearn import metrics\n",
    "\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data loading"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[★data는 여기에★](https://www.kaggle.com/samdeeplearning/deepnlp)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('Sheet_1.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style>\n",
       "    .dataframe thead tr:only-child th {\n",
       "        text-align: right;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: left;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>response_id</th>\n",
       "      <th>class</th>\n",
       "      <th>response_text</th>\n",
       "      <th>Unnamed: 3</th>\n",
       "      <th>Unnamed: 4</th>\n",
       "      <th>Unnamed: 5</th>\n",
       "      <th>Unnamed: 6</th>\n",
       "      <th>Unnamed: 7</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>response_1</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>I try and avoid this sort of conflict</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>response_2</td>\n",
       "      <td>flagged</td>\n",
       "      <td>Had a friend open up to me about his mental ad...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>response_3</td>\n",
       "      <td>flagged</td>\n",
       "      <td>I saved a girl from suicide once. She was goin...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>response_4</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>i cant think of one really...i think i may hav...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>response_5</td>\n",
       "      <td>not_flagged</td>\n",
       "      <td>Only really one friend who doesn't fit into th...</td>\n",
       "      <td></td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "      <td>NaN</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "  response_id        class                                      response_text  \\\n",
       "0  response_1  not_flagged              I try and avoid this sort of conflict   \n",
       "1  response_2      flagged  Had a friend open up to me about his mental ad...   \n",
       "2  response_3      flagged  I saved a girl from suicide once. She was goin...   \n",
       "3  response_4  not_flagged  i cant think of one really...i think i may hav...   \n",
       "4  response_5  not_flagged  Only really one friend who doesn't fit into th...   \n",
       "\n",
       "  Unnamed: 3  Unnamed: 4 Unnamed: 5  Unnamed: 6 Unnamed: 7  \n",
       "0        NaN         NaN        NaN         NaN        NaN  \n",
       "1        NaN         NaN        NaN         NaN        NaN  \n",
       "2        NaN         NaN        NaN         NaN        NaN  \n",
       "3        NaN         NaN        NaN         NaN        NaN  \n",
       "4                    NaN        NaN         NaN        NaN  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x = data['response_text']\n",
    "y = [1 if x == 'flagged' else 0 for x in data['class'] ] # flagged -> 1, not flagged -> 0"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Model & Detail about model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "아래 소스는 다음의 github를 보고 썼다.\n",
    "\n",
    "소스 코드 출처:<br>\n",
    "https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/text_classification.py\n",
    "\n",
    "약간 지나칠 정도로 설명을 해놨으므로 가독성이 떨어질 수도 있다ㅠㅠ<br>\n",
    "부제(?)를 나름 크게 해놨으니까 아는거다 싶으면 휙휙 넘어가면 된다!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### embedding size는 얼마로 할까?\n",
    "- word2vec 같은 neural network에서는 보통 크기를 300~500으로 셋팅한다고 한다.<br>\n",
    " 하지만, 자신의 data가 매우 적고 토이 모델 수준이라면 굳이 많이 할 필요가 없다.<br>\n",
    " embedding size가 클수록 vector의 차원이 늘어나므로 계산량이 확 늘어나기 때문이다.<br>\n",
    " 오랜 시간이 걸릴지라도 최고의 결과를 내고싶다! 이런 사람들은 500정도 주면 되지 않을까...?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "FLAGS = None\n",
    "\n",
    "MAX_DOCUMENT_LENGTH = 25 # 문서의 최대 길이. 길이가 1~25사이에 몰려 있어서 이렇게 했다.\n",
    "\n",
    "EMBEDDING_SIZE = 20 # 단어를 벡터로 바꿔주는 것이 (Word) embedding 이다. 이 embedding의 크기를 얼마로 해주는지 설정해준다. \n",
    "                    # 많지 않은 데이터의 경우 차원을 크게 해주면 오히려 공간에서 흩어지므로 좋지 않을 것 같다.\n",
    "n_words = 0\n",
    "\n",
    "MAX_LABEL = 2 # 0 or 1\n",
    "\n",
    "WORDS_FEATURE = 'words'  # Name of the input words feature. feature naming에 사용되므로, 큰 의미가 있는 것 같지는 않다.(아마도...?)\n",
    "\n",
    "learning_rate = 0.01"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## estimator\n",
    "- train, test, evaluation mode를 한번에 지정해주는 단계이다.\n",
    "\n",
    "#### 함수의 특징을 잘 모른다면...!\n",
    "- 보통 파이썬 문법에서 여러 가지의 케이스가 있을 때는 if, elif, else와 같이 케이스를 나누는데 아래의 코드에서는 if만 쓰던가 혹은 아무것도 쓰지 않는다. 그 이유는 굳이 쓸 필요가 없기 때문이다. <br> 함수 내부에서 return을 만나면 이후에 코드가 남았든 반복문 안이든 간에 프로그램은 함수를 빠져나온다. 즉, 함수가 필요한 값을 돌려주고 끝난다는 소리이다. <br>아래의 코드를 예로 들자면, Mode가 PREDICT인 경우 이후에 있는 그 다음 if문 부터의 코드는 수행되지 않는다.\n",
    "\n",
    "#### tf.estimator.EstimatorSpec\n",
    "- estimator specification의 약자같다.<br> 메서드를 정의 해놓고 이후의 코드에서 해당 메서드에 mode값만 다르게 주면 알아서 train, test, evaluation을 해주기 위해서 만들어진 듯 싶다.<br> 실행 부분에서 코드의 간결성을 주는 메서드 같다.\n",
    "\n",
    "#### tf.one_hot\n",
    "- one_hot(indices, depth, on_value=None, off_value=None, axis=None, dtype=None, name=None)<br>\n",
    " depth만큼의 크기를 가지는 vector에서, indices에 해당하는 index값에 on_value를 주고 그 외의 값에는 off_value를 주겠다는 뜻이다.<br>\n",
    " 해당 코드에서는 2열 짜리 vector에서 lable에 해당하는 index값에 1을 그 외의 값을 0으로 하겠다는 뜻이다. (사실 1과 0은 default값)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def estimator_spec_for_softmax_classification(logits, labels, mode):\n",
    "\n",
    "    \"Returns EstimatorSpec instance for softmax classification.\"\n",
    "\n",
    "    predicted_classes = tf.argmax(logits, 1)\n",
    "        \n",
    "    # case 1) inference mode\n",
    "    \n",
    "    # ModeKey가 PREDICT이면 inference mode이다. inference는 학습시킨 모델을 새로운 데이터에 적용시키는 것을 말한다.\n",
    "    if mode == tf.estimator.ModeKeys.PREDICT: \n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode=mode, predictions={'class': predicted_classes, 'prob': tf.nn.softmax(logits)})\n",
    "\n",
    "    \n",
    "    # case 2) training mode\n",
    "    \n",
    "    onehot_labels = tf.one_hot(labels, MAX_LABEL, 1, 0) \n",
    "\n",
    "    loss = tf.losses.softmax_cross_entropy(onehot_labels=onehot_labels, logits=logits)    \n",
    "    \n",
    "    if mode == tf.estimator.ModeKeys.TRAIN:\n",
    "\n",
    "        optimizer = tf.train.AdamOptimizer(learning_rate=learning_rate)\n",
    "\n",
    "        train_op = optimizer.minimize(loss, global_step=tf.train.get_global_step())\n",
    "\n",
    "        return tf.estimator.EstimatorSpec(mode, loss=loss, train_op=train_op)\n",
    "\n",
    "\n",
    "    # case 3) evaluation mode\n",
    "    \n",
    "    eval_metric_ops = {'accuracy': tf.metrics.accuracy(labels=labels, predictions=predicted_classes)}\n",
    "\n",
    "    return tf.estimator.EstimatorSpec(mode=mode, loss=loss, eval_metric_ops=eval_metric_ops)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## rnn_model\n",
    "- input 데이터를 embedding 시켜주고, neural network를 구성하는 단계이다. 마지막 결과를 softmax를 통해 0~1의 값으로 반환하는 단계이다.\n",
    "\n",
    "#### tf.contrib.layers.embed_sequence\n",
    "\n",
    "- symbols의 순서를 embeddings의 순서로 mapping 해주는 method.<br>\n",
    "  embedded sequences를 가지는 [batch_size, doc_length, embed_dim]를 반환한다.<br>\n",
    "  embed_dim만큼의 크기를 가지는 벡터들이 document 혹은 sentence의 word 개수만큼 있고, <br> \n",
    "  document 혹은 sentence를 몇 개씩 짝 지어놓은 게 batch_size만큼 있다.\n",
    "  \n",
    "#### word_vectors & word_list\n",
    "![이해](http://i.imgur.com/Bjn2LRF.png)\n",
    "\n",
    "#### tf.layers.dense\n",
    "\n",
    "- outputs = activation(inputs.kernel + bias)의 연산을 수행한다. 만약 activation 함수를 주면 activation 함수의 input으로 해당 값이 들어간다.<br>\n",
    " kernel은 weight matrix이다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def rnn_model(features, labels, mode):\n",
    "\n",
    "    \"\"\"RNN model to predict from sequence of words to a class.\"\"\"\n",
    "    \n",
    "    # 단어들의 index를 embeddings로 바꾼다. \n",
    "    # [n_words(단어 개수), EMBEDDING_SIZE]의 크기를 가지는 matrix를 만들고 순서를 나타내는 단어들의 index를 \n",
    "    # [batch_size, sequence_length, EMBEDDING_SIZE]에 mapping 한다.\n",
    "    \n",
    "    # word_vectors와 word_list를 만든다.\n",
    "    word_vectors = tf.contrib.layers.embed_sequence(features[WORDS_FEATURE], vocab_size=n_words, embed_dim=EMBEDDING_SIZE)\n",
    "    word_list = tf.unstack(word_vectors, axis=1)\n",
    "\n",
    "    \n",
    "    # embedding size와 같은 hidden size를 가지는 GUR cell을 만든다.\n",
    "    cell = tf.contrib.rnn.GRUCell(EMBEDDING_SIZE)\n",
    "\n",
    "    \n",
    "    # MAX_DOCUMENT_LENGTH의 길이를 가지는 RNN을 만든다. 그리고 각 유닛에 input으로 word_list를 준다.\n",
    "    # (output, state)쌍이 return된다.\n",
    "    _, encoding = tf.contrib.rnn.static_rnn(cell, word_list, dtype=tf.float32)\n",
    "\n",
    "    # 마지막 유닛의 state 값을 softmax classification의 feature로 넘겨준다.\n",
    "    logits = tf.layers.dense(encoding, MAX_LABEL, activation=None)\n",
    "\n",
    "    return estimator_spec_for_softmax_classification(logits=logits, labels=labels, mode=mode)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## main\n",
    "\n",
    "- 이전에 정의한 다른 estimator, rnn_model과 같은 함수들을 불러와 실행시켜주는 단계이다.\n",
    "\n",
    "#### tf.contrib.learn.preprocessing.VocabularyProcessor\n",
    "\n",
    "- 문장의 길이를 우리가 원하는 sequence length로 맞추어 주는 method.<br>\n",
    "  문장을 길이가 MAX_DOCUMENT_LENGTH인 vector로 반환한다.<br>\n",
    "  만약 MAX_DOCUMENT_LENGTH보다 작다면 0 pad가 더해지고, 크다면 이후 값은 쓰지 않는다.<br>\n",
    "  Embedding 이전 단계의 데이터 형태이다.<br>\n",
    "  \n",
    "  ![rnn link](http://i.imgur.com/IDaLPgj.png)\n",
    "\n",
    "\n",
    "#### tf.estimator.Estimator\n",
    "\n",
    "- 지정해주는 모델을 적용하는 classifier를 만들어준다.<br>\n",
    "  Train, Test, Predict를 모두 실행시켜준다.<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def main(unused_argv):\n",
    "    global n_words\n",
    "    \n",
    "    # train data set, test data set을 나눠준다.\n",
    "    x_train, x_test, y_train, y_test = train_test_split(x, y, test_size = 0.2, random_state = 4)\n",
    "    x_train = np.array(x_train)\n",
    "    x_test = np.array(x_test)\n",
    "    y_train = np.array(y_train)\n",
    "    y_test = np.array(y_test) # tensorflow input으로 사용될 수 있는 자료형으로 변환시켜줘야 한다.\n",
    "    \n",
    "    # 단어들을 우리가 원하는 sequence length로 맞추어 준다.(embedding 해주기 전 단계) 위의 사진 참고\n",
    "    vocab_processor = tf.contrib.learn.preprocessing.VocabularyProcessor(MAX_DOCUMENT_LENGTH)\n",
    "    \n",
    "    x_transform_train = vocab_processor.fit_transform(x_train) # 둘의 차이는?\n",
    "    x_transform_test = vocab_processor.transform(x_test)\n",
    "    \n",
    "    x_train = np.array(list(x_transform_train))\n",
    "    x_test = np.array(list(x_transform_test))\n",
    "    \n",
    "    n_words = len(vocab_processor.vocabulary_)\n",
    "    print('Total words : %d', n_words)\n",
    "    \n",
    "    # 모델을 만들어준다.(여기서는 위에서 정의한 rnn_model을 사용한다.)\n",
    "    model_fn = rnn_model\n",
    "    classifier = tf.estimator.Estimator(model_fn=model_fn)\n",
    "    \n",
    "    # Train\n",
    "    train_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = {WORDS_FEATURE : x_train},\n",
    "        y = y_train,\n",
    "        batch_size = len(x_train),\n",
    "        num_epochs = None,\n",
    "        shuffle = True) # shuffle = True : \n",
    "    classifier.train(input_fn = train_input_fn, steps = 100)\n",
    "    \n",
    "    # Predict\n",
    "    test_input_fn = tf.estimator.inputs.numpy_input_fn(\n",
    "        x = {WORDS_FEATURE : x_test},\n",
    "        y = y_test,\n",
    "        num_epochs = 1,\n",
    "        shuffle = False)\n",
    "    predictions = classifier.predict(input_fn = test_input_fn)\n",
    "    y_predicted = np.array(list(p['class'] for p in predictions))\n",
    "    \n",
    "    # Score using tensorflow\n",
    "    score = classifier.evaluate(input_fn = test_input_fn)\n",
    "    print('Accuracy (tensorflow): {0:f}'.format(score['accuracy']))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 실행단계\n",
    "- 위에서 bow model(bag of word model(수요일에 진행))은 정의하지 않았으므로, 위에서 정의한 rnn_model을 사용하게 된다."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total words : %d 650\n",
      "INFO:tensorflow:Using default config.\n",
      "WARNING:tensorflow:Using temporary folder as model directory: C:\\Users\\nhm\\AppData\\Local\\Temp\\tmpzp_gogxa\n",
      "INFO:tensorflow:Using config: {'_model_dir': 'C:\\\\Users\\\\nhm\\\\AppData\\\\Local\\\\Temp\\\\tmpzp_gogxa', '_tf_random_seed': 1, '_save_summary_steps': 100, '_save_checkpoints_secs': 600, '_save_checkpoints_steps': None, '_session_config': None, '_keep_checkpoint_max': 5, '_keep_checkpoint_every_n_hours': 10000}\n",
      "INFO:tensorflow:Create CheckpointSaverHook.\n",
      "INFO:tensorflow:Saving checkpoints for 1 into C:\\Users\\nhm\\AppData\\Local\\Temp\\tmpzp_gogxa\\model.ckpt.\n",
      "INFO:tensorflow:loss = 0.73507, step = 1\n",
      "INFO:tensorflow:Saving checkpoints for 100 into C:\\Users\\nhm\\AppData\\Local\\Temp\\tmpzp_gogxa\\model.ckpt.\n",
      "INFO:tensorflow:Loss for final step: 5.99285e-05.\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\nhm\\AppData\\Local\\Temp\\tmpzp_gogxa\\model.ckpt-100\n",
      "INFO:tensorflow:Starting evaluation at 2017-08-11-16:28:07\n",
      "INFO:tensorflow:Restoring parameters from C:\\Users\\nhm\\AppData\\Local\\Temp\\tmpzp_gogxa\\model.ckpt-100\n",
      "INFO:tensorflow:Finished evaluation at 2017-08-11-16:28:08\n",
      "INFO:tensorflow:Saving dict for global step 100: accuracy = 0.75, global_step = 100, loss = 1.6403\n",
      "Accuracy (tensorflow): 0.750000\n"
     ]
    },
    {
     "ename": "SystemExit",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "An exception has occurred, use %tb to see the full traceback.\n",
      "\u001b[1;31mSystemExit\u001b[0m\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\nhm\\Anaconda3\\lib\\site-packages\\IPython\\core\\interactiveshell.py:2889: UserWarning: To exit: use 'exit', 'quit', or Ctrl-D.\n",
      "  warn(\"To exit: use 'exit', 'quit', or Ctrl-D.\", stacklevel=1)\n"
     ]
    }
   ],
   "source": [
    "if __name__ == '__main__':\n",
    "    parser = argparse.ArgumentParser()\n",
    "    parser.add_argument(\n",
    "        '--test_with_fake_data',\n",
    "        default = False,\n",
    "        help = 'Test the example code with fake data',\n",
    "        action = 'store_true')\n",
    "    parser.add_argument(\n",
    "        '--bow model',\n",
    "        default = False,\n",
    "        help = 'Run with BOW model instead of RNN',\n",
    "        action = 'store_true')\n",
    "    FLAGS, unparsed = parser.parse_known_args()\n",
    "    tf.app.run(main=main, argv = [sys.argv[0]] + unparsed)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 마무리!\n",
    "\n",
    "- Neural Network는 black box라고 한다. 결과가 나왔을 때, 왜 이런 결과가 나왔는지 모른다는 것이 딥러닝의 가장 큰 단점이 아닐까 싶다. <br>\n",
    "  위의 accuracy가 마음에 들지 않아서 hyper parameter를 조정해주면서 반복해보았지만 그렇게 큰 차이가 나지는 않았다. <br>\n",
    "  우리는 GRUCell을 사용했는데, 어쩌면 LSTM이 더 좋은 결과를 가져다 줄 지도 모르겠다. <br>\n",
    "  \n",
    "  \n",
    "- 이전까지는 단순한 모델이였기에 함수를 정의하지 않고, 순차적으로 딥러닝을 구현했다. 처음에 NN의 각 역할을 함수로 나눠서 정의한 후에, <br>\n",
    "  나중에 한번에 합친다는 것 자체가 어색했지만(지금까지 함수를 정의한 경험이 많이 없다.), 구현해보고 나니 왜 함수로 나누는지 알 수 있었다. <br>\n",
    "  \n",
    "- 마지막에 실행단계에서 error가 처음에 발생했는데, train, test data를 나눌 때 sklearn을 사용한 결과는 list여서 input으로 사용될 수 없었던 <br>\n",
    "  문제였다. 함수별로 나눈 덕에 빠르게 오류의 원인을 찾아낼 수 있었다. 또한 전체적인 구조가 눈에 확 들어와서 좋은 방법이라고 느낄 수 있었다."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true
   },
   "source": [
    "## Reference\n",
    "\n",
    "- https://www.quora.com/Which-is-better-for-text-classification-CNN-or-RNN-Which-areas-of-NLP-do-they-better-suit-to\n",
    "- https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/learn/text_classification.py\n",
    "- https://medium.com/@ilblackdragon/tensorflow-text-classification-615198df9231\n",
    "- https://stackoverflow.com/questions/40661684/tensorflow-vocabularyprocessor\n",
    "- https://github.com/hunkim/word-rnn-tensorflow/blob/master/model.py"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
